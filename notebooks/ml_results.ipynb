{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac475e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Machine Learning Baseline Models for Nepali Hate Speech Detection\n",
    "Implements: Logistic Regression, SVM, Naive Bayes, Random Forest\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "from utils.preprocessing import preprocess_for_ml_gru\n",
    "from utils.evaluation import (\n",
    "    compute_metrics, print_metrics, \n",
    "    plot_confusion_matrix, compare_models\n",
    ")\n",
    "\n",
    "\n",
    "def load_data(preprocessed=True):\n",
    "    \"\"\"Load train, val, test data.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" LOADING DATA\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    if preprocessed and os.path.exists('data/processed/train_preprocessed.json'):\n",
    "        print(\"Loading preprocessed data...\")\n",
    "        train_df = pd.read_json('data/processed/train_preprocessed.json')\n",
    "        val_df = pd.read_json('data/processed/val_preprocessed.json')\n",
    "        test_df = pd.read_json('data/processed/test_preprocessed.json')\n",
    "    else:\n",
    "        print(\"Loading raw data and preprocessing...\")\n",
    "        train_df = pd.read_json('data/train.json')\n",
    "        test_df = pd.read_json('data/test.json')\n",
    "        \n",
    "        # Create validation split\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        train_df, val_df = train_test_split(\n",
    "            train_df,\n",
    "            test_size=0.15,\n",
    "            stratify=train_df['Label_Multiclass'],\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Preprocess\n",
    "        print(\"Preprocessing data...\")\n",
    "        for df in [train_df, val_df, test_df]:\n",
    "            df['clean_comment'] = df['Comment'].apply(preprocess_for_ml_gru)\n",
    "    \n",
    "    print(f\"‚úì Data loaded!\")\n",
    "    print(f\"  Train: {len(train_df)} samples\")\n",
    "    print(f\"  Validation: {len(val_df)} samples\")\n",
    "    print(f\"  Test: {len(test_df)} samples\")\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "def prepare_features(train_df, val_df, test_df, max_features=5000, ngram_range=(1, 3)):\n",
    "    \"\"\"Create TF-IDF features.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" FEATURE EXTRACTION\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    print(f\"Creating TF-IDF features...\")\n",
    "    print(f\"  - N-gram range: {ngram_range}\")\n",
    "    print(f\"  - Max features: {max_features}\")\n",
    "    \n",
    "    # Initialize vectorizer\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=ngram_range,\n",
    "        max_features=max_features,\n",
    "        min_df=2,\n",
    "        max_df=0.95,\n",
    "        sublinear_tf=True\n",
    "    )\n",
    "    \n",
    "    # Extract text\n",
    "    X_train_texts = train_df['clean_comment']\n",
    "    X_val_texts = val_df['clean_comment']\n",
    "    X_test_texts = test_df['clean_comment']\n",
    "    \n",
    "    # Fit and transform\n",
    "    X_train = vectorizer.fit_transform(X_train_texts)\n",
    "    X_val = vectorizer.transform(X_val_texts)\n",
    "    X_test = vectorizer.transform(X_test_texts)\n",
    "    \n",
    "    print(f\"\\n‚úì Features created!\")\n",
    "    print(f\"  Train shape: {X_train.shape}\")\n",
    "    print(f\"  Val shape: {X_val.shape}\")\n",
    "    print(f\"  Test shape: {X_test.shape}\")\n",
    "    print(f\"  Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "    print(f\"  Sparsity: {(1.0 - X_train.nnz / (X_train.shape[0] * X_train.shape[1])) * 100:.2f}%\")\n",
    "    \n",
    "    return X_train, X_val, X_test, vectorizer\n",
    "\n",
    "\n",
    "def prepare_labels(train_df, val_df, test_df):\n",
    "    \"\"\"Encode labels.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" LABEL ENCODING\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Initialize encoder\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Fit on training labels\n",
    "    le.fit(train_df['Label_Multiclass'])\n",
    "    \n",
    "    # Transform all sets\n",
    "    y_train = le.transform(train_df['Label_Multiclass'])\n",
    "    y_val = le.transform(val_df['Label_Multiclass'])\n",
    "    y_test = le.transform(test_df['Label_Multiclass'])\n",
    "    \n",
    "    print(f\"Label mapping:\")\n",
    "    for idx, label in enumerate(le.classes_):\n",
    "        print(f\"  {label} ‚Üí {idx}\")\n",
    "    \n",
    "    # Compute class weights\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nClass weights (for imbalance):\")\n",
    "    for label, weight in zip(le.classes_, class_weights):\n",
    "        print(f\"  {label}: {weight:.4f}\")\n",
    "    \n",
    "    class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "    \n",
    "    return y_train, y_val, y_test, le, class_weight_dict\n",
    "\n",
    "\n",
    "def train_logistic_regression(X_train, y_train, X_val, y_val, X_test, y_test, \n",
    "                              class_weight_dict, le, save_dir):\n",
    "    \"\"\"Train Logistic Regression model.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" TRAINING: LOGISTIC REGRESSION\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    model = LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight=class_weight_dict,\n",
    "        random_state=42,\n",
    "        solver='lbfgs',\n",
    "        C=1.0\n",
    "    )\n",
    "    \n",
    "    print(\"Training model...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"‚úì Training complete!\")\n",
    "    \n",
    "    # Validation performance\n",
    "    print(\"\\nValidation Set Performance:\")\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_metrics = compute_metrics(y_val, y_val_pred, labels=le.classes_)\n",
    "    print_metrics(val_metrics, title=\"Logistic Regression - Validation\")\n",
    "    \n",
    "    # Test performance\n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_metrics = compute_metrics(y_test, y_test_pred, labels=le.classes_)\n",
    "    print_metrics(test_metrics, title=\"Logistic Regression - Test\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plot_confusion_matrix(\n",
    "        y_test, y_test_pred,\n",
    "        labels=le.classes_,\n",
    "        save_path=os.path.join(save_dir, 'lr_confusion_matrix.png'),\n",
    "        title=\"Logistic Regression - Confusion Matrix\"\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(model, os.path.join(save_dir, 'logistic_regression_model.pkl'))\n",
    "    print(f\"‚úì Model saved to {save_dir}/logistic_regression_model.pkl\")\n",
    "    \n",
    "    return model, test_metrics\n",
    "\n",
    "\n",
    "def train_svm(X_train, y_train, X_val, y_val, X_test, y_test, \n",
    "              class_weight_dict, le, save_dir):\n",
    "    \"\"\"Train SVM model.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" TRAINING: SUPPORT VECTOR MACHINE\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    model = LinearSVC(\n",
    "        class_weight=class_weight_dict,\n",
    "        random_state=42,\n",
    "        max_iter=2000,\n",
    "        C=1.0,\n",
    "        loss='hinge'\n",
    "    )\n",
    "    \n",
    "    print(\"Training model...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"‚úì Training complete!\")\n",
    "    \n",
    "    # Validation performance\n",
    "    print(\"\\nValidation Set Performance:\")\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_metrics = compute_metrics(y_val, y_val_pred, labels=le.classes_)\n",
    "    print_metrics(val_metrics, title=\"SVM - Validation\")\n",
    "    \n",
    "    # Test performance\n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_metrics = compute_metrics(y_test, y_test_pred, labels=le.classes_)\n",
    "    print_metrics(test_metrics, title=\"SVM - Test\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plot_confusion_matrix(\n",
    "        y_test, y_test_pred,\n",
    "        labels=le.classes_,\n",
    "        save_path=os.path.join(save_dir, 'svm_confusion_matrix.png'),\n",
    "        title=\"SVM - Confusion Matrix\"\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(model, os.path.join(save_dir, 'svm_model.pkl'))\n",
    "    print(f\"‚úì Model saved to {save_dir}/svm_model.pkl\")\n",
    "    \n",
    "    return model, test_metrics\n",
    "\n",
    "\n",
    "def train_naive_bayes(X_train, y_train, X_val, y_val, X_test, y_test, \n",
    "                      le, save_dir):\n",
    "    \"\"\"Train Naive Bayes with SMOTE.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" TRAINING: NAIVE BAYES (with SMOTE)\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Apply SMOTE\n",
    "    print(\"Applying SMOTE oversampling...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    print(f\"  Original train size: {X_train.shape[0]}\")\n",
    "    print(f\"  Resampled train size: {X_train_res.shape[0]}\")\n",
    "    \n",
    "    model = MultinomialNB(alpha=1.0)\n",
    "    \n",
    "    print(\"\\nTraining model...\")\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    print(\"‚úì Training complete!\")\n",
    "    \n",
    "    # Validation performance\n",
    "    print(\"\\nValidation Set Performance:\")\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_metrics = compute_metrics(y_val, y_val_pred, labels=le.classes_)\n",
    "    print_metrics(val_metrics, title=\"Naive Bayes - Validation\")\n",
    "    \n",
    "    # Test performance\n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_metrics = compute_metrics(y_test, y_test_pred, labels=le.classes_)\n",
    "    print_metrics(test_metrics, title=\"Naive Bayes - Test\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plot_confusion_matrix(\n",
    "        y_test, y_test_pred,\n",
    "        labels=le.classes_,\n",
    "        save_path=os.path.join(save_dir, 'nb_confusion_matrix.png'),\n",
    "        title=\"Naive Bayes - Confusion Matrix\"\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(model, os.path.join(save_dir, 'naive_bayes_model.pkl'))\n",
    "    print(f\"‚úì Model saved to {save_dir}/naive_bayes_model.pkl\")\n",
    "    \n",
    "    return model, test_metrics\n",
    "\n",
    "\n",
    "def train_random_forest(X_train, y_train, X_val, y_val, X_test, y_test, \n",
    "                       class_weight_dict, le, save_dir):\n",
    "    \"\"\"Train Random Forest model.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" TRAINING: RANDOM FOREST\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight=class_weight_dict,\n",
    "        random_state=42,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(\"Training model...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"‚úì Training complete!\")\n",
    "    \n",
    "    # Validation performance\n",
    "    print(\"\\nValidation Set Performance:\")\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_metrics = compute_metrics(y_val, y_val_pred, labels=le.classes_)\n",
    "    print_metrics(val_metrics, title=\"Random Forest - Validation\")\n",
    "    \n",
    "    # Test performance\n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_metrics = compute_metrics(y_test, y_test_pred, labels=le.classes_)\n",
    "    print_metrics(test_metrics, title=\"Random Forest - Test\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plot_confusion_matrix(\n",
    "        y_test, y_test_pred,\n",
    "        labels=le.classes_,\n",
    "        save_path=os.path.join(save_dir, 'rf_confusion_matrix.png'),\n",
    "        title=\"Random Forest - Confusion Matrix\"\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(model, os.path.join(save_dir, 'random_forest_model.pkl'))\n",
    "    print(f\"‚úì Model saved to {save_dir}/random_forest_model.pkl\")\n",
    "    \n",
    "    return model, test_metrics\n",
    "\n",
    "\n",
    "def compare_all_models(results_dict, save_dir):\n",
    "    \"\"\"Compare all trained models.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" MODEL COMPARISON\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    comparison_data = []\n",
    "    for model_name, metrics in results_dict.items():\n",
    "        comparison_data.append({\n",
    "            'Model': model_name,\n",
    "            'Accuracy': f\"{metrics['accuracy']:.4f}\",\n",
    "            'Macro F1': f\"{metrics['macro_f1']:.4f}\",\n",
    "            'Weighted F1': f\"{metrics['weighted_f1']:.4f}\",\n",
    "            'NO F1': f\"{metrics['per_class']['NO']['f1']:.4f}\",\n",
    "            'OO F1': f\"{metrics['per_class']['OO']['f1']:.4f}\",\n",
    "            'OR F1': f\"{metrics['per_class']['OR']['f1']:.4f}\",\n",
    "            'OS F1': f\"{metrics['per_class']['OS']['f1']:.4f}\"\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    print(\"Test Set Performance Comparison:\")\n",
    "    print(\"=\"*70)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Save comparison table\n",
    "    comparison_df.to_csv(os.path.join(save_dir, 'ml_baselines_comparison.csv'), index=False)\n",
    "    print(f\"\\n‚úì Comparison table saved to {save_dir}/ml_baselines_comparison.csv\")\n",
    "    \n",
    "    # Find best model\n",
    "    macro_f1_values = {name: metrics['macro_f1'] for name, metrics in results_dict.items()}\n",
    "    best_model = max(macro_f1_values, key=macro_f1_values.get)\n",
    "    best_f1 = macro_f1_values[best_model]\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Model: {best_model}\")\n",
    "    print(f\"   Macro F1: {best_f1:.4f}\")\n",
    "    \n",
    "    # Visualize comparison\n",
    "    try:\n",
    "        compare_models(\n",
    "            {name: {'macro_f1': metrics['macro_f1']} for name, metrics in results_dict.items()},\n",
    "            metric='macro_f1',\n",
    "            save_path=os.path.join(save_dir, 'ml_comparison_chart.png')\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Could not create comparison chart: {str(e)}\")\n",
    "    \n",
    "    return comparison_df, best_model\n",
    "\n",
    "\n",
    "def save_artifacts(vectorizer, le, save_dir):\n",
    "    \"\"\"Save vectorizer and label encoder.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" SAVING ARTIFACTS\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    vectorizer_path = os.path.join(save_dir, 'tfidf_vectorizer.pkl')\n",
    "    le_path = os.path.join(save_dir, 'label_encoder.pkl')\n",
    "    \n",
    "    joblib.dump(vectorizer, vectorizer_path)\n",
    "    joblib.dump(le, le_path)\n",
    "    \n",
    "    print(f\"‚úì TF-IDF vectorizer saved to {vectorizer_path}\")\n",
    "    print(f\"‚úì Label encoder saved to {le_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training pipeline for ML baselines.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" MACHINE LEARNING BASELINES - TRAINING PIPELINE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create save directory\n",
    "    save_dir = 'models/saved_models'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Step 1: Load data\n",
    "    train_df, val_df, test_df = load_data(preprocessed=False)\n",
    "    \n",
    "    # Step 2: Prepare features\n",
    "    X_train, X_val, X_test, vectorizer = prepare_features(\n",
    "        train_df, val_df, test_df,\n",
    "        max_features=5000,\n",
    "        ngram_range=(1, 3)\n",
    "    )\n",
    "    \n",
    "    # Step 3: Prepare labels\n",
    "    y_train, y_val, y_test, le, class_weight_dict = prepare_labels(\n",
    "        train_df, val_df, test_df\n",
    "    )\n",
    "    \n",
    "    # Step 4: Train models\n",
    "    results = {}\n",
    "    \n",
    "    # Logistic Regression\n",
    "    lr_model, lr_metrics = train_logistic_regression(\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "        class_weight_dict, le, save_dir\n",
    "    )\n",
    "    results['Logistic Regression'] = lr_metrics\n",
    "    \n",
    "    # SVM\n",
    "    svm_model, svm_metrics = train_svm(\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "        class_weight_dict, le, save_dir\n",
    "    )\n",
    "    results['SVM'] = svm_metrics\n",
    "    \n",
    "    # Naive Bayes\n",
    "    nb_model, nb_metrics = train_naive_bayes(\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "        le, save_dir\n",
    "    )\n",
    "    results['Naive Bayes'] = nb_metrics\n",
    "    \n",
    "    # Random Forest\n",
    "    rf_model, rf_metrics = train_random_forest(\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "        class_weight_dict, le, save_dir\n",
    "    )\n",
    "    results['Random Forest'] = rf_metrics\n",
    "    \n",
    "    # Step 5: Compare models\n",
    "    comparison_df, best_model = compare_all_models(results, save_dir)\n",
    "    \n",
    "    # Step 6: Save artifacts\n",
    "    save_artifacts(vectorizer, le, save_dir)\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" TRAINING COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nüìä Summary:\")\n",
    "    print(f\"  Models trained: {len(results)}\")\n",
    "    print(f\"  Best model: {best_model}\")\n",
    "    print(f\"  Best Macro F1: {results[best_model]['macro_f1']:.4f}\")\n",
    "    print(f\"\\n  Model performance:\")\n",
    "    for model_name, metrics in results.items():\n",
    "        print(f\"    {model_name:<20} Macro F1: {metrics['macro_f1']:.4f}  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n‚úì Models saved to: {save_dir}/\")\n",
    "    print(f\"‚úì Comparison table: {save_dir}/ml_baselines_comparison.csv\")\n",
    "    print(f\"‚úì Confusion matrices: {save_dir}/*_confusion_matrix.png\")\n",
    "    \n",
    "    print(\"\\nüöÄ Next Steps:\")\n",
    "    print(\"  1. Review confusion matrices for error analysis\")\n",
    "    print(\"  2. Check per-class F1 scores for minority classes (OR, OS)\")\n",
    "    print(\"  3. Proceed to deep learning models: python scripts/3_gru_model.py\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        results = main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è  Training interrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\n‚ùå Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
